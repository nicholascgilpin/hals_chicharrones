{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "from __future__ import print_function\n",
    "import neat\n",
    "import visualize\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Flatten, Dense, Input, LSTM, Embedding, Dropout, Activation, SpatialDropout1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D,GlobalMaxPooling1D,GlobalAveragePooling1D ,Conv1D, MaxPooling1D, GRU,CuDNNLSTM,CuDNNGRU, Reshape, MaxPooling1D,AveragePooling1D\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "########################################\n",
    "## set directories and parameters\n",
    "########################################\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "#from keras import initializations\n",
    "from keras import initializers, regularizers, constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program Parameters\n",
    "TRAIN_DATA_FILE = \"train.csv\"\n",
    "ga_config = \"ga_config.txt\" # Parameters for the genetic algorithm\n",
    "max_features = 250000 # Maximum Number of Words in Dictionary\n",
    "maxlen = 300   # Maximum Sequence Size\n",
    "\n",
    "# Genetic Algorithm Hyperparameters\n",
    "max_generations = 300\n",
    "limit = 100 # limit number of rows to train per network\n",
    "# Note: limit must match fitness_threshold in ga_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from train.csv\n",
      ".\n",
      ".\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Load Files\n",
    "print (\"Loading Data from \" + str(TRAIN_DATA_FILE))\n",
    "final_validation_file = pd.read_csv(TRAIN_DATA_FILE)[:176230]  # (176230)\n",
    "print(\".\")\n",
    "test_df = pd.read_csv(TRAIN_DATA_FILE)[176231:511230] # (335000)\n",
    "print(\".\")\n",
    "train_df = pd.read_csv(TRAIN_DATA_FILE)[511231:1672297]\n",
    "print(\"done!\")\n",
    "total_rows = len(train_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               ReviewText  Rating\n",
      "511231  Only had it for 2 weeks, but so far it seems f...       4\n",
      "511232  Great to deal with this company.  Turned out m...       5\n",
      "511233  It does the job for a very low price what more...       5\n",
      "511234  My brother will be very happy, I gave him my H...       5\n",
      "511235  I do not subject my battery to a lot of wear a...       2\n",
      "Total rows:  1161066\n"
     ]
    }
   ],
   "source": [
    "# Data preview\n",
    "print(train_df.head())\n",
    "print(\"Total rows: \", total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare Data \n",
      ".\n",
      ".\n",
      ".\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Prepare Data \")\n",
    "print(\".\")\n",
    "list_sentences_train = train_df[\"ReviewText\"].fillna(\"NA\").values\n",
    "list_classes = [\"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"]\n",
    "num_classes=5\n",
    "print(\".\")\n",
    "#y = train_df[list_classes].values\n",
    "target=train_df['Rating'].values\n",
    "y1=to_categorical(target)\n",
    "y=np.delete(y1, 0, axis=1)\n",
    "print(\".\")\n",
    "list_sentences_test = test_df[\"ReviewText\"].fillna(\"NA\").values\n",
    "yaux=y[:,[0]]\n",
    "print(\"done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training sentences into arrays of words \n",
    "\n",
    "comments = []\n",
    "for text in list_sentences_train:\n",
    "    comments.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test sentences into arrays of words \n",
    "\n",
    "test_comments=[]\n",
    "for text in list_sentences_test:\n",
    "    test_comments.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an index and summary of words in word arrays\n",
      "Convert arrays of words into bag-of-word arrays\n"
     ]
    }
   ],
   "source": [
    "print(\"Create an index and summary of words in word arrays\")\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(comments + test_comments)\n",
    "\n",
    "print(\"Convert arrays of words into bag-of-word arrays\")\n",
    "sequences = tokenizer.texts_to_sequences(comments)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print a summary of data\n",
      "1161066 train sequences\n",
      "334999 test sequences\n",
      "Average train sequence length: 119\n",
      "Average test sequence length: 118\n",
      "1161066 train sequences\n",
      "334999 test sequences\n",
      "Max train sequence length: 6344\n",
      "Max test sequence length: 5626\n",
      "1161066 train sequences\n",
      "334999 test sequences\n",
      "Min train sequence length: 0\n",
      "Min test sequence length: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Print a summary of data\")\n",
    "print(len(sequences), 'train sequences')\n",
    "print(len(test_sequences), 'test sequences')\n",
    "print('Average train sequence length: {}'.format(np.mean(list(map(len, sequences)), dtype=int)))\n",
    "print('Average test sequence length: {}'.format(np.mean(list(map(len, test_sequences)), dtype=int)))\n",
    "print(len(sequences), 'train sequences')\n",
    "print(len(test_sequences), 'test sequences')\n",
    "print('Max train sequence length: {}'.format(np.max(list(map(len, sequences)))))\n",
    "print('Max test sequence length: {}'.format(np.max(list(map(len, test_sequences)))))\n",
    "print(len(sequences), 'train sequences')\n",
    "print(len(test_sequences), 'test sequences')\n",
    "print('Min train sequence length: {}'.format(np.min(list(map(len, sequences)))))\n",
    "print('Min test sequence length: {}'.format(np.min(list(map(len, test_sequences)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example conversion of text to padded Sequence:\n",
      "Only had it for 2 weeks, but so far it seems functional. While editing photos (pushing the computer hard) the battery lasts 2.5'ish hours.Placed it in a Dv6 1030 laptop.\n",
      "[     0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0     56     42\n",
      "      6     10     71    579     18     22    161      6    206   1371\n",
      "    128   1577    454   2366      1    126    150      1    109   1520\n",
      "     71 205189    337   1257      6     12      5  10586  18823    143]\n"
     ]
    }
   ],
   "source": [
    "print(\"Example conversion of text to padded Sequence:\")\n",
    "print(comments[0])\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 508584 unique tokens\n",
      "Shape of data tensor: (1161066, 300)\n",
      "Shape of label tensor: (1161066, 5)\n",
      "Shape of test_data tensor: (334999, 300)\n"
     ]
    }
   ],
   "source": [
    "# Name word index\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "# Format data so that it'll fit into the neural network\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', y.shape)\n",
    "\n",
    "test_data = pad_sequences(test_sequences, maxlen=maxlen)\n",
    "print('Shape of test_data tensor:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the fitness function for a genome as the accuracy of its neural network\n",
    "# Evaluates the fitness by building and testing the evolved neural network\n",
    "\n",
    "def eval_genomes(genomes, config):\n",
    "    for genome_id, genome in genomes:\n",
    "        genome.fitness = limit # max possible fitness \n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        for xi, xo in zip(data[:limit], y[:limit]):\n",
    "            output = net.activate(xi)\n",
    "            genome.fitness -= (output[0] - xo[0]) ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the genetic algorithm\n",
    "def run_ga(config_file):\n",
    "    # Load configuration.\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_file)\n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    p = neat.Population(config)\n",
    "\n",
    "    # Add a stdout reporter to show progress in the terminal.\n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "    p.add_reporter(neat.Checkpointer(5))\n",
    "\n",
    "    # Run for up to 300 generations.\n",
    "    winner = p.run(eval_genomes, max_generations)\n",
    "\n",
    "    # Display the winning genome (Very ugly)\n",
    "    # print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "\n",
    "    # Show output of the most fit genome against training data.\n",
    "    print('\\nOutput:')\n",
    "    winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "    for xi, xo in zip(data[:limit], y[:limit]):\n",
    "        output = winner_net.activate(xi)\n",
    "        print(\"input {!r}, expected output {!r}, got {!r}\".format(xi, xo, output))\n",
    "\n",
    "#     visualize.draw_net(config, winner, True)\n",
    "#     visualize.plot_stats(stats, ylog=False, view=True)\n",
    "#     visualize.plot_species(stats, view=True)\n",
    "\n",
    "#     p = neat.Checkpointer.restore_checkpoint('neat-checkpoint-4')\n",
    "    p.run(eval_genomes, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "Population's average fitness: 49.52667 stdev: 9.96306\n",
      "Best fitness: 75.00000 - size: (5, 1500) - species 1 - id 19\n",
      "Average adjusted fitness: 0.491\n",
      "Mean genetic distance 1.287, standard deviation 0.195\n",
      "Population of 150 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    0   150     75.0    0.491     0\n",
      "Total extinctions: 0\n",
      "Generation time: 46.077 sec\n",
      "\n",
      " ****** Running generation 1 ****** \n",
      "\n",
      "Population's average fitness: 60.04664 stdev: 7.56955\n",
      "Best fitness: 76.00000 - size: (6, 1497) - species 1 - id 213\n",
      "Average adjusted fitness: 0.591\n",
      "Mean genetic distance 1.360, standard deviation 0.199\n",
      "Population of 150 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    1   150     76.0    0.591     0\n",
      "Total extinctions: 0\n",
      "Generation time: 43.485 sec (44.781 average)\n",
      "\n",
      " ****** Running generation 2 ****** \n",
      "\n",
      "Population's average fitness: 67.98581 stdev: 6.20304\n",
      "Best fitness: 82.00000 - size: (5, 1476) - species 1 - id 302\n",
      "Average adjusted fitness: 0.533\n",
      "Mean genetic distance 1.280, standard deviation 0.196\n",
      "Population of 150 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    2   150     82.0    0.533     0\n",
      "Total extinctions: 0\n",
      "Generation time: 45.552 sec (45.038 average)\n",
      "\n",
      " ****** Running generation 3 ****** \n",
      "\n",
      "Population's average fitness: 70.90743 stdev: 5.35621\n",
      "Best fitness: 82.00000 - size: (5, 1476) - species 1 - id 302\n",
      "Average adjusted fitness: 0.642\n",
      "Mean genetic distance 1.294, standard deviation 0.191\n",
      "Population of 150 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    3   150     82.0    0.642     1\n",
      "Total extinctions: 0\n",
      "Generation time: 43.366 sec (44.620 average)\n",
      "\n",
      " ****** Running generation 4 ****** \n",
      "\n",
      "Population's average fitness: 72.69895 stdev: 5.44617\n",
      "Best fitness: 83.00000 - size: (6, 1461) - species 1 - id 606\n",
      "Average adjusted fitness: 0.588\n",
      "Mean genetic distance 1.348, standard deviation 0.184\n",
      "Population of 150 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    4   150     83.0    0.588     0\n",
      "Total extinctions: 0\n",
      "Generation time: 45.092 sec (44.714 average)\n",
      "Saving checkpoint to neat-checkpoint-4\n",
      "\n",
      " ****** Running generation 5 ****** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_ga(ga_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chatbot)",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
